{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid BP classes: 1927\n",
      "Number of valid MF classes: 478\n",
      "Number of valid CC classes: 316\n",
      "Number of valid proteins: 3409\n",
      "Valid entities saved to: PDB_test_set/valid_classes_and_proteins.pkl\n",
      "Label dictionaries saved to PDB_test_set.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "# DeepFri\n",
    "with open(\"model_outputs/DeepFri/bp/_BP_pred_scores.json\", 'r') as f:\n",
    "    deepfri_bp_dict = json.load(f)\n",
    "deepfri_bp_classes = deepfri_bp_dict['goterms']\n",
    "deepfri_proteins = deepfri_bp_dict['pdb_chains']\n",
    "\n",
    "with open(\"model_outputs/DeepFri/mf/_MF_pred_scores.json\", 'r') as f:\n",
    "    deepfri_mf_dict = json.load(f)\n",
    "deepfri_mf_classes = deepfri_mf_dict['goterms']\n",
    "\n",
    "with open(\"model_outputs/DeepFri/cc/_CC_pred_scores.json\", 'r') as f:\n",
    "    deepfri_cc_dict = json.load(f)\n",
    "deepfri_cc_classes = deepfri_cc_dict['goterms']\n",
    "\n",
    "\n",
    "# HEAL\n",
    "heal_bp_classes = list(pickle.load(open(\"model_outputs/HEAL/bp/1A0P-A.pkl\", \"rb\")).keys())\n",
    "heal_mf_classes = list(pickle.load(open(\"model_outputs/HEAL/mf/1A0P-A.pkl\", \"rb\")).keys())\n",
    "heal_cc_classes = list(pickle.load(open(\"model_outputs/HEAL/cc/1A0P-A.pkl\", \"rb\")).keys())\n",
    "\n",
    "heal_proteins = [i.split(\".\")[0] for i in os.listdir('model_outputs/HEAL/bp')]\n",
    "\n",
    "# PFresGO\n",
    "pfresgo_bp_classes = list(pickle.load(open(\"model_outputs/PFresGO/BP_PFresGO_results.pckl\", \"rb\"))['goterms'])\n",
    "pfresgo_mf_classes = list(pickle.load(open(\"model_outputs/PFresGO/MF_PFresGO_results.pckl\", \"rb\"))['goterms'])\n",
    "pfresgo_cc_classes = list(pickle.load(open(\"model_outputs/PFresGO/CC_PFresGO_results.pckl\", \"rb\"))['goterms'])\n",
    "\n",
    "pfresgo_proteins = list(pickle.load(open(\"model_outputs/PFresGO/BP_PFresGO_results.pckl\", \"rb\"))['proteins'])\n",
    "\n",
    "\n",
    "valid_bp_classes = list(set(deepfri_bp_classes) & set(heal_bp_classes) & set(pfresgo_bp_classes))\n",
    "valid_mf_classes = list(set(deepfri_mf_classes) & set(heal_mf_classes) & set(pfresgo_mf_classes))\n",
    "valid_cc_classes = list(set(deepfri_cc_classes) & set(heal_cc_classes) & set(pfresgo_cc_classes))\n",
    "\n",
    "#GoBERT\n",
    "gobert_proteins = list(pickle.load(open(\"model_outputs/GoBERT/processed/GoBERT_BP_logits.pkl\", \"rb\")).keys())\n",
    "# Find overlapping proteins\n",
    "valid_proteins = list(set(deepfri_proteins) & set(heal_proteins) & set(pfresgo_proteins) & set(gobert_proteins))\n",
    "\n",
    "# Summary of results\n",
    "print(f\"Number of valid BP classes: {len(valid_bp_classes)}\")\n",
    "print(f\"Number of valid MF classes: {len(valid_mf_classes)}\")\n",
    "print(f\"Number of valid CC classes: {len(valid_cc_classes)}\")\n",
    "print(f\"Number of valid proteins: {len(valid_proteins)}\")\n",
    "\n",
    "valid_dict = {\n",
    "    \"valid_proteins\": valid_proteins,\n",
    "    \"valid_bp_classes\": valid_bp_classes,\n",
    "    \"valid_mf_classes\": valid_mf_classes,\n",
    "    \"valid_cc_classes\": valid_cc_classes\n",
    "}\n",
    "\n",
    "output_path = \"PDB_test_set/valid_classes_and_proteins.pkl\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, 'wb') as pkl_file:\n",
    "    pickle.dump(valid_dict, pkl_file)\n",
    "\n",
    "print(f\"Valid entities saved to: {output_path}\")\n",
    "\n",
    "data_path = \"PDB_test_set/nrPDB-GO_2019.06.18_annot.tsv\"\n",
    "output_dir = \"PDB_test_set\"\n",
    "\n",
    "# Initialize dictionaries with all zeros\n",
    "bp_labels = {protein: {go: 0 for go in valid_bp_classes} for protein in valid_proteins}\n",
    "cc_labels = {protein: {go: 0 for go in valid_cc_classes} for protein in valid_proteins}\n",
    "mf_labels = {protein: {go: 0 for go in valid_mf_classes} for protein in valid_proteins}\n",
    "\n",
    "# Load the TSV annotation file\n",
    "annotations = pd.read_csv(data_path, sep='\\t', header=None,\n",
    "                           names=[\"PDB-chain\", \"GO-terms (molecular_function)\", \n",
    "                                  \"GO-terms (biological_process)\", \"GO-terms (cellular_component)\"])\n",
    "\n",
    "# Update the labels dictionaries based on the annotation file\n",
    "for _, row in annotations.iterrows():\n",
    "    protein = row[\"PDB-chain\"]\n",
    "\n",
    "    if protein in valid_proteins:\n",
    "        # Update MF labels\n",
    "        if isinstance(row[\"GO-terms (molecular_function)\"], str):\n",
    "            mf_terms = set(row[\"GO-terms (molecular_function)\"].split(','))\n",
    "            for go in mf_terms.intersection(valid_mf_classes):\n",
    "                mf_labels[protein][go] = 1\n",
    "\n",
    "        # Update BP labels\n",
    "        if isinstance(row[\"GO-terms (biological_process)\"], str):\n",
    "            bp_terms = set(row[\"GO-terms (biological_process)\"].split(','))\n",
    "            for go in bp_terms.intersection(valid_bp_classes):\n",
    "                bp_labels[protein][go] = 1\n",
    "\n",
    "        # Update CC labels\n",
    "        if isinstance(row[\"GO-terms (cellular_component)\"], str):\n",
    "            cc_terms = set(row[\"GO-terms (cellular_component)\"].split(','))\n",
    "            for go in cc_terms.intersection(valid_cc_classes):\n",
    "                cc_labels[protein][go] = 1\n",
    "\n",
    "# Save the label dictionaries\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, \"BP_labels.pkl\"), 'wb') as bp_file:\n",
    "    pickle.dump(bp_labels, bp_file)\n",
    "\n",
    "with open(os.path.join(output_dir, \"CC_labels.pkl\"), 'wb') as cc_file:\n",
    "    pickle.dump(cc_labels, cc_file)\n",
    "\n",
    "with open(os.path.join(output_dir, \"MF_labels.pkl\"), 'wb') as mf_file:\n",
    "    pickle.dump(mf_labels, mf_file)\n",
    "\n",
    "print(f\"Label dictionaries saved to {output_dir}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess DeepFri output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3410/3410 [01:33<00:00, 36.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: model_outputs/DeepFri/processed/DeepFri_BP_logits.pkl with 3409 proteins and 1927 GO classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3410/3410 [00:02<00:00, 1321.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: model_outputs/DeepFri/processed/DeepFri_CC_logits.pkl with 3409 proteins and 316 GO classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3410/3410 [00:06<00:00, 504.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: model_outputs/DeepFri/processed/DeepFri_MF_logits.pkl with 3409 proteins and 478 GO classes.\n",
      "Processing with constraints completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "def process_deepfri_scores(input_json_path, output_pkl_path, valid_proteins, valid_classes):\n",
    "    \"\"\"\n",
    "    Processes the DeepFri JSON file and saves the results as a dictionary in a .pkl file.\n",
    "    Filters based on valid proteins and classes.\n",
    "    \n",
    "    Args:\n",
    "        input_json_path (str): Path to the input JSON file.\n",
    "        output_pkl_path (str): Path to save the processed .pkl file.\n",
    "        valid_proteins (list): List of valid proteins to include.\n",
    "        valid_classes (list): List of valid GO classes to include.\n",
    "    \"\"\"\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        deepfri_dict = json.load(f)\n",
    "    \n",
    "    # Extract relevant keys\n",
    "    pdb_chains = deepfri_dict['pdb_chains']\n",
    "    y_hat = deepfri_dict['Y_hat']\n",
    "    goterms = deepfri_dict['goterms']\n",
    "\n",
    "    # Filter proteins and classes\n",
    "    filtered_dict = {\n",
    "        chain: {goterm: y_hat[idx][gidx] for gidx, goterm in enumerate(goterms) if goterm in valid_classes}\n",
    "        for idx, chain in tqdm(enumerate(pdb_chains), total=len(pdb_chains)) if chain in valid_proteins\n",
    "    }\n",
    "\n",
    "    # Save the processed dictionary as a .pkl file\n",
    "    os.makedirs(os.path.dirname(output_pkl_path), exist_ok=True)\n",
    "    with open(output_pkl_path, 'wb') as pkl_file:\n",
    "        pickle.dump(filtered_dict, pkl_file)\n",
    "    \n",
    "    print(f\"Processed data saved to: {output_pkl_path} with {len(filtered_dict)} proteins and {len(list(filtered_dict.values())[0])} GO classes.\")\n",
    "\n",
    "# Paths for DeepFri files\n",
    "file_paths = {\n",
    "    \"bp\": {\n",
    "        \"input\": \"model_outputs/DeepFri/bp/_BP_pred_scores.json\",\n",
    "        \"output\": \"model_outputs/DeepFri/processed/DeepFri_BP_logits.pkl\"\n",
    "    },\n",
    "    \"cc\": {\n",
    "        \"input\": \"model_outputs/DeepFri/cc/_CC_pred_scores.json\",\n",
    "        \"output\": \"model_outputs/DeepFri/processed/DeepFri_CC_logits.pkl\"\n",
    "    },\n",
    "    \"mf\": {\n",
    "        \"input\": \"model_outputs/DeepFri/mf/_MF_pred_scores.json\",\n",
    "        \"output\": \"model_outputs/DeepFri/processed/DeepFri_MF_logits.pkl\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load valid classes and proteins\n",
    "valid_dict = pickle.load(open(\"PDB_test_set/valid_classes_and_proteins.pkl\", \"rb\"))\n",
    "valid_proteins = valid_dict[\"valid_proteins\"]\n",
    "valid_bp_classes = valid_dict[\"valid_bp_classes\"]\n",
    "valid_mf_classes = valid_dict[\"valid_mf_classes\"]\n",
    "valid_cc_classes = valid_dict[\"valid_cc_classes\"]\n",
    "\n",
    "# Process each file with constraints\n",
    "process_deepfri_scores(file_paths['bp']['input'], file_paths['bp']['output'], valid_proteins, valid_bp_classes)\n",
    "process_deepfri_scores(file_paths['cc']['input'], file_paths['cc']['output'], valid_proteins, valid_cc_classes)\n",
    "process_deepfri_scores(file_paths['mf']['input'], file_paths['mf']['output'], valid_proteins, valid_mf_classes)\n",
    "\n",
    "print(\"Processing with constraints completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess HEAL output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HEAL BP outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3410/3410 [00:38<00:00, 89.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed HEAL data saved to: model_outputs/HEAL/processed/HEAL_BP_logits.pkl with 3409 proteins and 1927 GO classes.\n",
      "Processing HEAL CC outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3410/3410 [00:01<00:00, 2751.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed HEAL data saved to: model_outputs/HEAL/processed/HEAL_CC_logits.pkl with 3409 proteins and 316 GO classes.\n",
      "Processing HEAL MF outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3410/3410 [00:02<00:00, 1270.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed HEAL data saved to: model_outputs/HEAL/processed/HEAL_MF_logits.pkl with 3409 proteins and 478 GO classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "def process_heal_outputs(input_folder, output_pkl_path, valid_proteins, valid_classes):\n",
    "    \"\"\"\n",
    "    Processes the HEAL outputs stored as separate .pkl files and combines them\n",
    "    into a dictionary where the key is the pdb_chain and the value is a nested\n",
    "    dictionary with GO terms and logits. Filters based on valid proteins and classes.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing HEAL .pkl files.\n",
    "        output_pkl_path (str): Path to save the combined dictionary as a .pkl file.\n",
    "        valid_proteins (list): List of valid proteins to include.\n",
    "        valid_classes (list): List of valid GO classes to include.\n",
    "    \"\"\"\n",
    "    combined_dict = {}\n",
    "\n",
    "    # Iterate over all .pkl files in the input folder\n",
    "    for filename in tqdm(os.listdir(input_folder)):\n",
    "        if filename.endswith('.pkl'):\n",
    "            pdb_chain = filename.split('.')[0]  # Extract pdb_chain (e.g., '1A0P-A')\n",
    "            if pdb_chain not in valid_proteins:\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Load the .pkl file\n",
    "            data = pickle.load(open(file_path, \"rb\"))\n",
    "\n",
    "            # Filter data for valid classes\n",
    "            filtered_data = {goterm: logit for goterm, logit in data.items() if goterm in valid_classes}\n",
    "\n",
    "            if filtered_data:  # Add only if there are valid classes\n",
    "                combined_dict[pdb_chain] = filtered_data\n",
    "\n",
    "    # Save the combined dictionary as a .pkl file\n",
    "    os.makedirs(os.path.dirname(output_pkl_path), exist_ok=True)\n",
    "    with open(output_pkl_path, 'wb') as pkl_file:\n",
    "        pickle.dump(combined_dict, pkl_file)\n",
    "\n",
    "    print(f\"Processed HEAL data saved to: {output_pkl_path} with {len(combined_dict)} proteins and {len(list(combined_dict.values())[0])} GO classes.\")\n",
    "\n",
    "# Define input folders and output paths\n",
    "heal_paths = {\n",
    "    \"bp\": (\"model_outputs/HEAL/bp\", \"model_outputs/HEAL/processed/HEAL_BP_logits.pkl\"),\n",
    "    \"cc\": (\"model_outputs/HEAL/cc\", \"model_outputs/HEAL/processed/HEAL_CC_logits.pkl\"),\n",
    "    \"mf\": (\"model_outputs/HEAL/mf\", \"model_outputs/HEAL/processed/HEAL_MF_logits.pkl\")\n",
    "}\n",
    "\n",
    "# Load valid classes and proteins\n",
    "valid_dict = pickle.load(open(\"PDB_test_set/valid_classes_and_proteins.pkl\", \"rb\"))\n",
    "valid_proteins = valid_dict[\"valid_proteins\"]\n",
    "valid_bp_classes = valid_dict[\"valid_bp_classes\"]\n",
    "valid_mf_classes = valid_dict[\"valid_mf_classes\"]\n",
    "valid_cc_classes = valid_dict[\"valid_cc_classes\"]\n",
    "\n",
    "# Process HEAL outputs for each category\n",
    "print(\"Processing HEAL BP outputs...\")\n",
    "process_heal_outputs(heal_paths[\"bp\"][0], heal_paths[\"bp\"][1], valid_proteins, valid_bp_classes)\n",
    "\n",
    "print(\"Processing HEAL CC outputs...\")\n",
    "process_heal_outputs(heal_paths[\"cc\"][0], heal_paths[\"cc\"][1], valid_proteins, valid_cc_classes)\n",
    "\n",
    "print(\"Processing HEAL MF outputs...\")\n",
    "process_heal_outputs(heal_paths[\"mf\"][0], heal_paths[\"mf\"][1], valid_proteins, valid_mf_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess PFresGO output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PFresGO BP outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3416/3416 [00:37<00:00, 90.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: model_outputs/PFresGO/processed/PFresGO_BP_logits.pkl with 3409 proteins and 1927 GO classes.\n",
      "Processing PFresGO CC outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3416/3416 [00:01<00:00, 2275.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: model_outputs/PFresGO/processed/PFresGO_CC_logits.pkl with 3409 proteins and 316 GO classes.\n",
      "Processing PFresGO MF outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3416/3416 [00:02<00:00, 1175.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: model_outputs/PFresGO/processed/PFresGO_MF_logits.pkl with 3409 proteins and 478 GO classes.\n",
      "Processing with constraints completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def process_pfresgo_scores(input_pkl_path, output_pkl_path, valid_proteins, valid_classes):\n",
    "    \"\"\"\n",
    "    Processes the PFresGO .pckl file and saves the results as a dictionary in a .pkl file.\n",
    "    Filters based on valid proteins and classes.\n",
    "\n",
    "    Args:\n",
    "        input_pkl_path (str): Path to the input .pckl file.\n",
    "        output_pkl_path (str): Path to save the processed .pkl file.\n",
    "        valid_proteins (list): List of valid proteins to include.\n",
    "        valid_classes (list): List of valid GO classes to include.\n",
    "    \"\"\"\n",
    "    # Load the PFresGO data\n",
    "    data = pickle.load(open(input_pkl_path, \"rb\"))\n",
    "\n",
    "    # Extract relevant keys\n",
    "    proteins = data['proteins']\n",
    "    y_hat = data['Y_pred']\n",
    "    goterms = data['goterms']\n",
    "\n",
    "    # Create the nested dictionary\n",
    "    processed_dict = {}\n",
    "    for idx, protein in tqdm(enumerate(proteins), total=len(proteins)):\n",
    "        if protein not in valid_proteins:\n",
    "            continue\n",
    "\n",
    "        filtered_data = {goterm: y_hat[idx][gidx] for gidx, goterm in enumerate(goterms) if goterm in valid_classes}\n",
    "\n",
    "        if filtered_data:  # Add only if there are valid classes\n",
    "            processed_dict[protein] = filtered_data\n",
    "\n",
    "    # Save the processed dictionary as a .pkl file\n",
    "    os.makedirs(os.path.dirname(output_pkl_path), exist_ok=True)\n",
    "    with open(output_pkl_path, 'wb') as pkl_file:\n",
    "        pickle.dump(processed_dict, pkl_file)\n",
    "\n",
    "    print(f\"Processed data saved to: {output_pkl_path} with {len(processed_dict)} proteins and {len(list(processed_dict.values())[0])} GO classes.\")\n",
    "\n",
    "# Paths for PFresGO files\n",
    "file_paths = {\n",
    "    \"bp\": {\n",
    "        \"input\": \"model_outputs/PFresGO/BP_PFresGO_results.pckl\",\n",
    "        \"output\": \"model_outputs/PFresGO/processed/PFresGO_BP_logits.pkl\"\n",
    "    },\n",
    "    \"cc\": {\n",
    "        \"input\": \"model_outputs/PFresGO/CC_PFresGO_results.pckl\",\n",
    "        \"output\": \"model_outputs/PFresGO/processed/PFresGO_CC_logits.pkl\"\n",
    "    },\n",
    "    \"mf\": {\n",
    "        \"input\": \"model_outputs/PFresGO/MF_PFresGO_results.pckl\",\n",
    "        \"output\": \"model_outputs/PFresGO/processed/PFresGO_MF_logits.pkl\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load valid classes and proteins\n",
    "valid_dict = pickle.load(open(\"PDB_test_set/valid_classes_and_proteins.pkl\", \"rb\"))\n",
    "valid_proteins = valid_dict[\"valid_proteins\"]\n",
    "valid_bp_classes = valid_dict[\"valid_bp_classes\"]\n",
    "valid_mf_classes = valid_dict[\"valid_mf_classes\"]\n",
    "valid_cc_classes = valid_dict[\"valid_cc_classes\"]\n",
    "\n",
    "# Process each file\n",
    "print(\"Processing PFresGO BP outputs...\")\n",
    "process_pfresgo_scores(file_paths[\"bp\"][\"input\"], file_paths[\"bp\"][\"output\"], valid_proteins, valid_bp_classes)\n",
    "\n",
    "print(\"Processing PFresGO CC outputs...\")\n",
    "process_pfresgo_scores(file_paths[\"cc\"][\"input\"], file_paths[\"cc\"][\"output\"], valid_proteins, valid_cc_classes)\n",
    "\n",
    "print(\"Processing PFresGO MF outputs...\")\n",
    "process_pfresgo_scores(file_paths[\"mf\"][\"input\"], file_paths[\"mf\"][\"output\"], valid_proteins, valid_mf_classes)\n",
    "\n",
    "print(\"Processing with constraints completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GoBERT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GoBERT logits for BP, there are 3409 proteins and 193 GO classes\n",
      "Checking GoBERT logits for MF, there are 3409 proteins and 48 GO classes\n",
      "Checking GoBERT logits for CC, there are 3409 proteins and 33 GO classes\n"
     ]
    }
   ],
   "source": [
    "for i in ['BP', 'MF', 'CC']:\n",
    "    data = pickle.load(open(f\"model_outputs/GoBERT/processed/GoBERT_{i}_logits.pkl\", \"rb\"))\n",
    "    print(f\"Checking GoBERT logits for {i}, there are {len(data)} proteins and {len(list(data.values())[0])} GO classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate propogate Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obonet\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "\n",
    "def pregenerate_GO_propogation(labels_dict_path, output_path):\n",
    "    graph = obonet.read_obo('PDB_test_set/go-basic.obo')\n",
    "\n",
    "    # Convert the graph to a directed graph\n",
    "    go_graph = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with attributes\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        go_graph.add_node(node, **data)\n",
    "\n",
    "    # Add edges\n",
    "    for source, target in graph.edges():\n",
    "        go_graph.add_edge(source, target)\n",
    "\n",
    "    labels_dict = pickle.load(open(labels_dict_path, \"rb\"))\n",
    "    output_dict = {}\n",
    "    goterms = list(next(iter(labels_dict.values())).keys())\n",
    "    for goterm in tqdm(goterms):\n",
    "        output_dict[goterm] = nx.descendants(go_graph, goterm)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(output_dict, f)\n",
    "\n",
    "for subgraph in ['BP', \"MF\", \"CC\"]:\n",
    "    pregenerate_GO_propogation(labels_dict_path=f\"PDB_test_set/{subgraph}_labels.pkl\", output_path=f\"PDB_test_set/{subgraph}_propogate_dict.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
